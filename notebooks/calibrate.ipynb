{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import multiprocessing as mp\n",
    "import platform\n",
    "if platform.system() != \"Windows\": mp.set_start_method('spawn')\n",
    "\n",
    "from tb_incubator.constants import set_project_base_path, ImplementCDR, BURN_IN\n",
    "from tb_incubator.calibrate import get_bcm, get_all_priors\n",
    "from tb_incubator.utils import get_next_run_number, get_next_run_number_for_config\n",
    "\n",
    "from estival.wrappers import pymc as epm\n",
    "from estival.sampling import tools as esamp\n",
    "import arviz as az\n",
    "\n",
    "from estival.utils.sample import SampleTypes\n",
    "import nevergrad as ng\n",
    "from estival.wrappers import nevergrad as eng\n",
    "from estival.utils.parallel import map_parallel\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"  \n",
    "project_paths = set_project_base_path(\"../tb_incubator/\")\n",
    "calib_out = project_paths[\"OUT_PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"start_population_size\": 1.0,\n",
    "    \"seed_time\": 1805.0,\n",
    "    \"seed_num\": 1.0,\n",
    "    \"seed_duration\": 1.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 10000\n",
    "tune = 10000\n",
    "draws = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(\n",
    "    out_path, params, draws, tune, \n",
    "    covid_effects = True, apply_diagnostic_capacity = True, xpert_improvement=True, apply_cdr=ImplementCDR.ON_NOTIFICATION\n",
    "):\n",
    "    bcm = get_bcm(\n",
    "        params = params, \n",
    "        covid_effects = covid_effects, \n",
    "        apply_diagnostic_capacity = apply_diagnostic_capacity,\n",
    "        xpert_improvement = xpert_improvement,\n",
    "        apply_cdr = apply_cdr)\n",
    "    run_number = get_next_run_number(out_path, draws, tune)\n",
    "    file_suffix = f'{draws}d{tune}t_{run_number}'\n",
    "\n",
    "    def optimize_ng_with_idx(item):\n",
    "        idx, sample = item\n",
    "        opt = eng.optimize_model(bcm, budget=500, opt_class=ng.optimizers.TwoPointsDE, suggested = sample, num_workers=8)\n",
    "        rec= opt.minimize(500)\n",
    "        return idx, rec.value[1]\n",
    "\n",
    "    lhs_samples = bcm.sample.lhs(16, ci=0.67)\n",
    "    lhs_lle = esamp.likelihood_extras_for_samples(lhs_samples, bcm)\n",
    "    lhs_sorted = lhs_lle.sort_values(\"loglikelihood\", ascending=False)\n",
    "    opt_samples_idx = map_parallel(optimize_ng_with_idx, lhs_sorted.iterrows())\n",
    "    best_opt_samps = bcm.sample.convert(opt_samples_idx)\n",
    "    init_samps = best_opt_samps.convert(SampleTypes.LIST_OF_DICTS)[0:8]\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        variables = epm.use_model(bcm)\n",
    "        idata = pm.sample(step=[pm.DEMetropolisZ(variables)], draws=draws, tune=tune,cores=16,chains=8, initvals=init_samps, mp_ctx=\"spawn\")\n",
    "    idata.to_netcdf(str(out_path / f'calib_full_out_{file_suffix}.nc'))\n",
    "    \n",
    "    burnt_idata = idata.sel(draw=np.s_[burn_in:])\n",
    "    idata_extract = az.extract(burnt_idata, num_samples=1000)\n",
    "    bcm.sample.convert(idata_extract).to_hdf5(out_path / f'calib_extract_out_{file_suffix}.h5')\n",
    "\n",
    "    spaghetti_res = esamp.model_results_for_samples(idata_extract, bcm) \n",
    "    spaghetti_res.results.to_hdf(path_or_buf = str(out_path / f\"results_{file_suffix}.hdf\"), key = \"spaghetti\")\n",
    "\n",
    "    like_df = esamp.likelihood_extras_for_idata(idata, bcm)\n",
    "    like_df.to_hdf(path_or_buf= str(out_path / f'results_{file_suffix}.hdf'), key = 'likelihood')\n",
    "\n",
    "    with open(out_path / f'config_for{file_suffix}.txt', 'w') as file:\n",
    "        # Header\n",
    "        file.write(f\"Calibration Configuration - {file_suffix}\\n\")\n",
    "        file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        \n",
    "        # Model settings\n",
    "        file.write(\"MODEL SETTINGS:\\n\")\n",
    "        file.write(f\"  COVID effects: {covid_effects}\\n\")\n",
    "        file.write(f\"  Diagnostic capacity: {apply_diagnostic_capacity}\\n\")\n",
    "        file.write(f\"  CDR implementation: {apply_cdr}\\n\")\n",
    "        file.write(f\"  Xpert improvement: {xpert_improvement}\\n\")\n",
    "        \n",
    "        # Calibration settings\n",
    "        file.write(f\"\\nCALIBRATION SETTINGS:\\n\")\n",
    "        file.write(f\"  Draws: {draws}\\n\")\n",
    "        file.write(f\"  Tune: {tune}\\n\")\n",
    "        \n",
    "        # Priors\n",
    "        priors = get_all_priors(\n",
    "            covid_effects=covid_effects,\n",
    "            apply_diagnostic_capacity=apply_diagnostic_capacity,\n",
    "            apply_cdr=apply_cdr, \n",
    "            xpert_improvement=xpert_improvement\n",
    "        )\n",
    "        \n",
    "        for prior in priors:\n",
    "            bounds = prior.bounds()\n",
    "            file.write(f\"  {prior.name}: {bounds[0]:.3f} to {bounds[1]:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_with_configs(out_path, params, draws, tune, model_configs, covid_effects = True):\n",
    "    for config_name, model_config in model_configs.items():\n",
    "        bcm = get_bcm(\n",
    "            params = params, \n",
    "            covid_effects = covid_effects, \n",
    "            **model_config)\n",
    "\n",
    "        run_number = get_next_run_number_for_config(out_path, draws, tune, model_configs)\n",
    "        file_suffix = f'{config_name}_{draws}d{tune}t_{run_number}nr'\n",
    "\n",
    "        def optimize_ng_with_idx(item):\n",
    "            idx, sample = item\n",
    "            opt = eng.optimize_model(bcm, budget=500, opt_class=ng.optimizers.TwoPointsDE, suggested = sample, num_workers=8)\n",
    "            rec= opt.minimize(500)\n",
    "            return idx, rec.value[1]\n",
    "\n",
    "        lhs_samples = bcm.sample.lhs(16, ci=0.67)\n",
    "        lhs_lle = esamp.likelihood_extras_for_samples(lhs_samples, bcm)\n",
    "        lhs_sorted = lhs_lle.sort_values(\"loglikelihood\", ascending=False)\n",
    "        opt_samples_idx = map_parallel(optimize_ng_with_idx, lhs_sorted.iterrows())\n",
    "        best_opt_samps = bcm.sample.convert(opt_samples_idx)\n",
    "        init_samps = best_opt_samps.convert(SampleTypes.LIST_OF_DICTS)[0:8]\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            variables = epm.use_model(bcm)\n",
    "            idata_raw = pm.sample(step=[pm.DEMetropolisZ(variables)], draws=draws, tune=tune,cores=16,chains=8, initvals=init_samps, mp_ctx=\"spawn\")\n",
    "        idata_raw.to_netcdf(str(out_path / f'calib_full_out_{file_suffix}.nc'))\n",
    "        \n",
    "        burnt_idata = idata_raw.sel(draw=np.s_[BURN_IN:])\n",
    "        idata_extract = az.extract(burnt_idata, num_samples=1000)\n",
    "        bcm.sample.convert(idata_extract).to_hdf5(out_path / f'calib_extract_out_{file_suffix}.h5')\n",
    "\n",
    "        spaghetti_res = esamp.model_results_for_samples(idata_extract, bcm) \n",
    "        spaghetti_res.results.to_hdf(path_or_buf = str(out_path / f\"results_{file_suffix}.hdf\"), key = \"spaghetti\")\n",
    "\n",
    "        like_df = esamp.likelihood_extras_for_idata(idata_raw, bcm)\n",
    "        like_df.to_hdf(path_or_buf= str(out_path / f'results_{file_suffix}.hdf'), key = 'likelihood')\n",
    "        \n",
    "        # Extract config values from model_config\n",
    "        apply_diagnostic_capacity = model_config['apply_diagnostic_capacity']\n",
    "        apply_cdr = model_config['apply_cdr']\n",
    "        xpert_improvement = model_config['xpert_improvement']\n",
    "\n",
    "        with open(out_path / f'config_for{file_suffix}.txt', 'w') as file:\n",
    "            # Header\n",
    "            file.write(f\"Calibration Configuration - {file_suffix}\\n\")\n",
    "            file.write(\"=\" * 50 + \"\\n\\n\")\n",
    "            \n",
    "            # Model settings\n",
    "            file.write(f\"  Config name: {config_name}\\n\")\n",
    "            file.write(\"MODEL SETTINGS:\\n\")\n",
    "            file.write(f\"  COVID effects: {covid_effects}\\n\")\n",
    "            file.write(f\"  Diag. capacity: {apply_diagnostic_capacity}\\n\")\n",
    "            file.write(f\"  CDR implementation: {apply_cdr}\\n\")\n",
    "            file.write(f\"  Xpert improvement: {xpert_improvement}\\n\")\n",
    "            \n",
    "            # Calibration settings\n",
    "            file.write(f\"\\nCALIBRATION SETTINGS:\\n\")\n",
    "            file.write(f\"  Draws: {draws}\\n\")\n",
    "            file.write(f\"  Tune: {tune}\\n\")\n",
    "            \n",
    "            # Priors\n",
    "            priors = get_all_priors(\n",
    "                covid_effects=covid_effects,\n",
    "                apply_diagnostic_capacity=apply_diagnostic_capacity,\n",
    "                apply_cdr=apply_cdr, \n",
    "                xpert_improvement=xpert_improvement\n",
    "            )\n",
    "            \n",
    "            for prior in priors:\n",
    "                bounds = prior.bounds()\n",
    "                file.write(f\"  {prior.name}: {bounds[0]:.3f} to {bounds[1]:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    'cdr_notif': { \n",
    "        'apply_diagnostic_capacity': True,\n",
    "        'xpert_improvement': True,\n",
    "        'apply_cdr': ImplementCDR.ON_NOTIFICATION,\n",
    "    },\n",
    "    'cdr_detect': {\n",
    "        'apply_diagnostic_capacity': True,\n",
    "        'xpert_improvement': True,\n",
    "        'apply_cdr': ImplementCDR.ON_DETECTION,\n",
    "    },\n",
    "    'no_cdr': {\n",
    "        'apply_diagnostic_capacity': True,\n",
    "        'xpert_improvement': True,\n",
    "        'apply_cdr': ImplementCDR.NONE,\n",
    "    },\n",
    "    'cdr_notif_noxpert': { \n",
    "        'apply_diagnostic_capacity': True,\n",
    "        'xpert_improvement': False,\n",
    "        'apply_cdr': ImplementCDR.ON_NOTIFICATION,\n",
    "    },\n",
    "    'cdr_detect_noxpert': {\n",
    "        'apply_diagnostic_capacity': True,\n",
    "        'xpert_improvement': False,\n",
    "        'apply_cdr': ImplementCDR.ON_DETECTION,\n",
    "    },\n",
    "    'no_cdr_noxpert': {\n",
    "        'apply_diagnostic_capacity': True,\n",
    "        'xpert_improvement': False,\n",
    "        'apply_cdr': ImplementCDR.NONE,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibrate(calib_out, params, draws, tune, covid_effects = True, apply_diagnostic_capacity = True, xpert_improvement = True, apply_cdr=ImplementCDR.ON_NOTIFICATION)\n",
    "calibrate_with_configs(calib_out, params, draws, tune, model_configs, covid_effects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbmodel310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
