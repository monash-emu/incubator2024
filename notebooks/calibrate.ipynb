{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import multiprocessing as mp\n",
    "import platform\n",
    "if platform.system() != \"Windows\":\n",
    "    mp.set_start_method('spawn')\n",
    "\n",
    "from tb_incubator.constants import set_project_base_path\n",
    "from tb_incubator.input import load_param_info\n",
    "from tb_incubator.calibrate import get_bcm, save_priors\n",
    "from tb_incubator.utils import get_next_run_number\n",
    "\n",
    "from estival.wrappers import pymc as epm\n",
    "from estival.sampling import tools as esamp\n",
    "import arviz as az\n",
    "\n",
    "from estival.utils.sample import SampleTypes\n",
    "import nevergrad as ng\n",
    "from estival.wrappers import nevergrad as eng\n",
    "from estival.utils.parallel import map_parallel\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"  \n",
    "project_paths = set_project_base_path(\"../tb_incubator/\")\n",
    "calib_out = project_paths[\"OUT_PATH\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    'xpert_only': { # cdr is used outside detection function (only when calculating notification)\n",
    "        'xpert_improvement': True,\n",
    "        'apply_cdr_within_model': False,\n",
    "    },\n",
    "    'no_xpert_no_cdr': { # cdr inside detection function\n",
    "        'xpert_improvement': False,\n",
    "        'apply_cdr_within_model': False,\n",
    "    },\n",
    "    'xpert_cdr_inside': {\n",
    "        'xpert_improvement': True,\n",
    "        'apply_cdr_within_model': True,\n",
    "    },\n",
    "    'cdr_inside': {\n",
    "        'xpert_improvement': False,\n",
    "        'apply_cdr_within_model': True,\n",
    "    },\n",
    "}\n",
    "\n",
    "params= load_param_info()[\"value\"]\n",
    "param_info = load_param_info()\n",
    "covid_effects = {\n",
    "    'detection_reduction':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "burn_in = 10000\n",
    "tune = 10000\n",
    "draws = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate(out_path, draws, tune, xpert_improvement, covid_effects, apply_cdr_within_model):\n",
    "    bcm = get_bcm(params, xpert_improvement=xpert_improvement, covid_effects=covid_effects, apply_cdr_within_model=apply_cdr_within_model)\n",
    "    run_number = get_next_run_number(out_path, draws, tune, model_configs)\n",
    "    file_suffix = f'{draws}d{tune}t_{run_number}'\n",
    "\n",
    "    def optimize_ng_with_idx(item):\n",
    "        idx, sample = item\n",
    "        opt = eng.optimize_model(bcm, budget=500, opt_class=ng.optimizers.TwoPointsDE, suggested = sample, num_workers=8)\n",
    "        rec= opt.minimize(500)\n",
    "        return idx, rec.value[1]\n",
    "\n",
    "    lhs_samples = bcm.sample.lhs(16, ci=0.67)\n",
    "    lhs_lle = esamp.likelihood_extras_for_samples(lhs_samples, bcm)\n",
    "    lhs_sorted = lhs_lle.sort_values(\"loglikelihood\", ascending=False)\n",
    "    opt_samples_idx = map_parallel(optimize_ng_with_idx, lhs_sorted.iterrows())\n",
    "    best_opt_samps = bcm.sample.convert(opt_samples_idx)\n",
    "    init_samps = best_opt_samps.convert(SampleTypes.LIST_OF_DICTS)[0:8]\n",
    "\n",
    "    with pm.Model() as model:\n",
    "        variables = epm.use_model(bcm)\n",
    "        idata = pm.sample(step=[pm.DEMetropolisZ(variables)], draws=draws, tune=tune,cores=16,chains=8, initvals=init_samps, mp_ctx=\"spawn\")\n",
    "    idata.to_netcdf(str(out_path / f'calib_full_out_{file_suffix}.nc'))\n",
    "    \n",
    "    burnt_idata = idata.sel(draw=np.s_[burn_in:])\n",
    "    idata_extract = az.extract(burnt_idata, num_samples=15)\n",
    "    bcm.sample.convert(idata_extract).to_hdf5(out_path / f'calib_extract_out_{file_suffix}.h5')\n",
    "\n",
    "    spaghetti_res = esamp.model_results_for_samples(idata_extract, bcm) \n",
    "    spaghetti_res.results.to_hdf(path_or_buf = str(out_path / f\"results_{file_suffix}.hdf\"), key = \"spaghetti\")\n",
    "\n",
    "    like_df = esamp.likelihood_extras_for_idata(idata, bcm)\n",
    "    like_df.to_hdf(path_or_buf= str(out_path / f'results_{file_suffix}.hdf'), key = 'likelihood')\n",
    "\n",
    "    return idata, file_suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_with_configs(out_path, params, model_configs, covid_effects, draws, tune):\n",
    "    for config_name, model_config in model_configs.items():\n",
    "        bcm = get_bcm(params, **model_config, covid_effects=covid_effects)\n",
    "\n",
    "        run_number = get_next_run_number(out_path, draws, tune, model_configs)\n",
    "        file_suffix = f'{config_name}_{draws}d{tune}t_{run_number}'\n",
    "\n",
    "        def optimize_ng_with_idx(item):\n",
    "            idx, sample = item\n",
    "            opt = eng.optimize_model(bcm, budget=500, opt_class=ng.optimizers.TwoPointsDE, suggested = sample, num_workers=8)\n",
    "            rec= opt.minimize(500)\n",
    "            return idx, rec.value[1]\n",
    "\n",
    "        lhs_samples = bcm.sample.lhs(16, ci=0.67)\n",
    "        lhs_lle = esamp.likelihood_extras_for_samples(lhs_samples, bcm)\n",
    "        lhs_sorted = lhs_lle.sort_values(\"loglikelihood\", ascending=False)\n",
    "        opt_samples_idx = map_parallel(optimize_ng_with_idx, lhs_sorted.iterrows())\n",
    "        best_opt_samps = bcm.sample.convert(opt_samples_idx)\n",
    "        init_samps = best_opt_samps.convert(SampleTypes.LIST_OF_DICTS)[0:8]\n",
    "\n",
    "        with pm.Model() as model:\n",
    "            variables = epm.use_model(bcm)\n",
    "            idata_raw = pm.sample(step=[pm.DEMetropolisZ(variables)], draws=draws, tune=tune,cores=16,chains=8, initvals=init_samps, mp_ctx=\"spawn\")\n",
    "        idata_raw.to_netcdf(str(out_path / f'calib_full_out_{file_suffix}.nc'))\n",
    "        \n",
    "        burnt_idata = idata_raw.sel(draw=np.s_[burn_in:])\n",
    "        idata_extract = az.extract(burnt_idata, num_samples=15)\n",
    "        bcm.sample.convert(idata_extract).to_hdf5(out_path / f'calib_extract_out_{file_suffix}.h5')\n",
    "\n",
    "        spaghetti_res = esamp.model_results_for_samples(idata_extract, bcm) \n",
    "        spaghetti_res.results.to_hdf(path_or_buf = str(out_path / f\"results_{file_suffix}.hdf\"), key = \"spaghetti\")\n",
    "\n",
    "        like_df = esamp.likelihood_extras_for_idata(idata_raw, bcm)\n",
    "        like_df.to_hdf(path_or_buf= str(out_path / f'results_{file_suffix}.hdf'), key = 'likelihood')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idata, file_suffix = calibrate(calib_out, 10000, 5000, 27, xpert_improvement=True, covid_effects=covid_effects)\n",
    "calibrate_with_configs(calib_out, params, model_configs, covid_effects, draws, tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tbmodel310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
